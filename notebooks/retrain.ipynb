{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T22:09:42.384511Z","iopub.status.busy":"2024-04-27T22:09:42.383772Z","iopub.status.idle":"2024-04-27T22:09:46.644419Z","shell.execute_reply":"2024-04-27T22:09:46.643469Z","shell.execute_reply.started":"2024-04-27T22:09:42.384480Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated 100000 orders.\n","Distribution Statistics:\n","\tNumber of Items: {'Min': 1, 'Max': 10, 'Average': 5.50567}\n"]}],"source":["import random\n","import string\n","\n","def generate_order(min_items=1, max_items=10):\n","  \"\"\"\n","  Generates a single order with a random number of items and unique item details.\n","  \"\"\"\n","  num_items = random.randint(min_items, max_items)\n","  order_id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10))\n","  item_list = []\n","  for _ in range(num_items):\n","    description = f\"Item {len(item_list) + 1}\"\n","    # Generate unique dimensions for each item\n","    dimensions = (random.uniform(5, 20), random.uniform(5, 20), random.uniform(1, 10))\n","    while any(dim in item_list for dim in dimensions):  # Check for duplicates\n","      dimensions = (random.uniform(5, 20), random.uniform(5, 20), random.uniform(1, 10))\n","    item_list.append({\"Description\": description, \"Dimensions (x, y, z)\": dimensions})\n","  return order_id, num_items, item_list\n","\n","def generate_data(num_orders=100000):\n","  \"\"\"\n","  Generates a list of 100,000 orders with unique item dimensions.\n","  \"\"\"\n","  data = []\n","  num_items_list = []\n","  # No need to track dimensions as they are guaranteed unique\n","\n","  for _ in range(num_orders):\n","    order_id, num_items, item_list = generate_order()\n","    data.append((order_id, num_items, item_list))\n","    num_items_list.append(num_items)\n","\n","  return data, {\n","      \"Number of Items\": {\n","          \"Min\": min(num_items_list),\n","          \"Max\": max(num_items_list),\n","          \"Average\": sum(num_items_list) / len(num_items_list)\n","      }\n","  }\n","\n","if __name__ == \"__main__\":\n","  data, statistics = generate_data()\n","  print(\"Generated\", len(data), \"orders.\")\n","  print(\"Distribution Statistics:\")\n","  for key, value in statistics.items():\n","    print(f\"\\t{key}: {value}\")\n","\n","  # Access data and statistics\n","  # data[0] - contains the first order details (order_id, num_items, item_list)\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T22:09:50.244415Z","iopub.status.busy":"2024-04-27T22:09:50.243817Z","iopub.status.idle":"2024-04-27T22:09:59.736346Z","shell.execute_reply":"2024-04-27T22:09:59.735355Z","shell.execute_reply.started":"2024-04-27T22:09:50.244383Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Data saved to orders.json\n"]}],"source":["import json\n","\n","# Assuming data is the generated list of orders\n","with open(\"orders.json\", \"w\") as f:\n","  json.dump(data, f)\n","\n","print(\"Data saved to orders.json\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T22:10:09.360790Z","iopub.status.busy":"2024-04-27T22:10:09.360467Z","iopub.status.idle":"2024-04-27T22:10:14.194542Z","shell.execute_reply":"2024-04-27T22:10:14.193649Z","shell.execute_reply.started":"2024-04-27T22:10:09.360764Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated 100000 orders.\n","Distribution Statistics:\n","\tNumber of Items: {'Min': 1, 'Max': 10, 'Average': 5.49866}\n","\tItem Dimensions: {'x': {'Min': 5.000000018940461, 'Max': 19.999507787153938, 'Average': 12.499680333938295}, 'y': {'Min': 5.000041970469566, 'Max': 19.999999708317844, 'Average': 12.503359722039859}, 'z': {'Min': 1.0000061112493257, 'Max': 9.999955149294676, 'Average': 5.505075709252739}}\n"]}],"source":["import random\n","import string\n","\n","def generate_order(min_items=1, max_items=10):\n","  \"\"\"\n","  Generates a single order with a random number of items and unique item details.\n","  \"\"\"\n","  num_items = random.randint(min_items, max_items)\n","  order_id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10))\n","  item_list = []\n","  for _ in range(num_items):\n","    description = f\"Item {len(item_list) + 1}\"\n","    # Generate unique dimensions for each item\n","    dimensions = (random.uniform(5, 20), random.uniform(5, 20), random.uniform(1, 10))\n","    while any(dim in item_list for dim in dimensions):  # Check for duplicates\n","      dimensions = (random.uniform(5, 20), random.uniform(5, 20), random.uniform(1, 10))\n","    item_list.append({\"Description\": description, \"Dimensions (x, y, z)\": dimensions})\n","  return order_id, num_items, item_list\n","\n","def generate_data(num_orders=100000):\n","  \"\"\"\n","  Generates a list of 100,000 orders with unique item dimensions, and calculates distribution statistics.\n","  \"\"\"\n","  data = []\n","  num_items_list = []\n","  dimensions_x = []\n","  dimensions_y = []\n","  dimensions_z = []\n","  \n","  for _ in range(num_orders):\n","    order_id, num_items, item_list = generate_order()\n","    data.append((order_id, num_items, item_list))\n","    num_items_list.append(num_items)\n","    dimensions_x.append(item_list[0][\"Dimensions (x, y, z)\"][0])  # Assuming first item for dimensions (can be modified)\n","    dimensions_y.append(item_list[0][\"Dimensions (x, y, z)\"][1])\n","    dimensions_z.append(item_list[0][\"Dimensions (x, y, z)\"][2])\n","\n","  return data, {\n","      \"Number of Items\": {\n","          \"Min\": min(num_items_list),\n","          \"Max\": max(num_items_list),\n","          \"Average\": sum(num_items_list) / len(num_items_list)\n","      },\n","      \"Item Dimensions\": {\n","          \"x\": {\n","              \"Min\": min(dimensions_x),\n","              \"Max\": max(dimensions_x),\n","              \"Average\": sum(dimensions_x) / len(dimensions_x)\n","          },\n","          \"y\": {\n","              \"Min\": min(dimensions_y),\n","              \"Max\": max(dimensions_y),\n","              \"Average\": sum(dimensions_y) / len(dimensions_y)\n","          },\n","          \"z\": {\n","              \"Min\": min(dimensions_z),\n","              \"Max\": max(dimensions_z),\n","              \"Average\": sum(dimensions_z) / len(dimensions_z)\n","          }\n","      }\n","  }\n","\n","if __name__ == \"__main__\":\n","  data, statistics = generate_data()\n","  print(\"Generated\", len(data), \"orders.\")\n","  print(\"Distribution Statistics:\")\n","  for key, value in statistics.items():\n","    print(f\"\\t{key}: {value}\")\n","\n","  # Access data and statistics\n","  # data[0] - contains the first order details (order_id, num_items, item_list)\n","  # statistics[\"Number of Items\"][\"Min\"] - minimum number of items per order\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T22:32:45.370602Z","iopub.status.busy":"2024-04-27T22:32:45.370115Z","iopub.status.idle":"2024-04-27T22:32:45.395004Z","shell.execute_reply":"2024-04-27T22:32:45.393932Z","shell.execute_reply.started":"2024-04-27T22:32:45.370566Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ok\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np\n","from spektral.layers import GCNConv\n","\n","def item_cnn(input_shape):\n","    inputs = keras.Input(shape=input_shape)  # Input for item dimensions\n","    if len(input_shape) == 3:  # Check if 3D input (no channels)\n","        x = tf.expand_dims(inputs, axis=-1)  # Add channel dimension\n","    else:\n","        x = inputs\n","\n","    kernel_size = min(2, input_shape[2])  # Adjust kernel size based on input shape\n","    x = layers.Conv3D(filters=32, kernel_size=kernel_size, activation=\"relu\")(x)\n","    x = layers.Conv3D(filters=32, kernel_size=kernel_size, activation=\"relu\")(x)\n","    x = layers.MaxPooling3D(pool_size=(2, 2, 2))(x)  # Downsample features\n","    x = layers.Conv3D(filters=64, kernel_size=kernel_size, activation=\"relu\")(x)\n","    x = layers.MaxPooling3D(pool_size=(2, 2, 2))(x)  # Further downsample\n","    x = layers.Flatten()(x)  # Convert to 1D vector for efficient combination\n","\n","    return keras.Model(inputs=inputs, outputs=x) # Convert to 1D vector for efficient combination\n","\n","def order_gnn(item_embedding_dim):\n","  \"\"\"\n","  Defines a GNN model for learning order representations.\n","  \"\"\"\n","  inputs = keras.Input(shape=(None,))  # Variable number of items in an order\n","  item_features = keras.Input(shape=(item_embedding_dim,))  # From item CNN\n","\n","  # Define the message passing function for the GNN layer\n","  def message(inputs):\n","    node_features, edge_index = inputs\n","    return tf.concat([node_features, edge_index[:, 1]], axis=-1)  # Combine node features with target node index\n","\n","  # Create the GNN layer with message passing function\n","  x = GCNConv(32, activation=\"relu\")(inputs=[item_features, inputs])\n","  # Additional GNN layers can be added for more complex relationships\n","  return keras.Model(inputs=[inputs, item_features], outputs=x)\n","\n","def combine_outputs(item_cnn_output, order_gnn_output):\n","  \"\"\"\n","  Combines the outputs from the item CNN and order GNN.\n","  \"\"\"\n","  x = layers.concatenate([item_cnn_output, order_gnn_output])\n","  return x\n","\n","def predict_box(combined_features):\n","  \"\"\"\n","  Predicts the optimal box dimensions and cost for a given order.\n","  \"\"\"\n","  x = layers.Dense(64, activation=\"relu\")(combined_features)  # Hidden layer for further processing\n","  box_dims = layers.Dense(3, activation=\"sigmoid\")(x)  # Predict normalized box dimensions (x, y, z)\n","  cost_factor = layers.Dense(1)(x)  # Predict cost factor based on predicted box volume (optional)\n","  return box_dims, cost_factor  # Optionally return cost factor\n","\n","def create_model(item_shape, item_embedding_dim):\n","  \"\"\"\n","  Creates and returns the complete model with 3D CNN, GNN, and prediction layers.\n","  \"\"\"\n","  item_shape_with_channels = (*item_shape, 1)  # Add channel dimension to item shape\n","  item_cnn_model = item_cnn(item_shape_with_channels)\n","  order_gnn_model = order_gnn(item_embedding_dim)\n","\n","  item_inputs = keras.Input(shape=item_shape_with_channels)  # Input for item dimensions\n","  order_inputs = keras.Input(shape=(None,))  # Input for order (number of items)\n","\n","  # Get item embeddings from the CNN\n","  item_embeddings = item_cnn_model(item_inputs)\n","\n","  # Encode order structure as a graph (left as an exercise for customization)\n","  # You'll need to define how items in an order are connected as a graph\n","  order_graph = ...  # Define the order graph based on item relationships\n","\n","  # Pass item embeddings and order graph through the GNN\n","  order_representation = order_gnn_model([order_graph, item_embeddings])\n","\n","  # Combine outputs from CNN and GNN\n","  combined_features = combine_outputs(item_embeddings, order_representation)\n","\n","  # Predict box dimensions and optionally cost factor\n","  box_dims, cost_factor = predict_box(combined_features)\n","\n","  model = keras.Model(inputs=[item_inputs, order_inputs], outputs=[box_dims, cost_factor])\n","  return model\n","print(\"ok\")"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T22:32:50.048652Z","iopub.status.busy":"2024-04-27T22:32:50.047947Z","iopub.status.idle":"2024-04-27T22:32:50.214660Z","shell.execute_reply":"2024-04-27T22:32:50.213087Z","shell.execute_reply.started":"2024-04-27T22:32:50.048611Z"},"trusted":true},"outputs":[{"ename":"ValueError","evalue":"Exception encountered when calling layer \"conv3d_8\" (type Conv3D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv3d_8/Conv3D}} = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1, 1]](Placeholder, conv3d_8/Conv3D/ReadVariableOp)' with input shapes: [?,4,4,1,32], [2,2,2,32,64].\n\nCall arguments received by layer \"conv3d_8\" (type Conv3D):\n  • inputs=tf.Tensor(shape=(None, 4, 4, 1, 32), dtype=float32)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 79\u001b[0m\n\u001b[1;32m     75\u001b[0m       train_data, validation_data \u001b[38;5;241m=\u001b[39m train_test_split(train_val_data, test_size\u001b[38;5;241m=\u001b[39mval_size\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mtest_size), random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     77\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m train_data, validation_data, test_data \u001b[38;5;66;03m# Implement data splitting function\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_embedding_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m train_model(model, train_data, validation_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test data (optional)\u001b[39;00m\n","Cell \u001b[0;32mIn[28], line 62\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(item_shape, item_embedding_dim)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mCreates and returns the complete model with 3D CNN, GNN, and prediction layers.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m item_shape_with_channels \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39mitem_shape, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add channel dimension to item shape\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m item_cnn_model \u001b[38;5;241m=\u001b[39m \u001b[43mitem_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_shape_with_channels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m order_gnn_model \u001b[38;5;241m=\u001b[39m order_gnn(item_embedding_dim)\n\u001b[1;32m     65\u001b[0m item_inputs \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39mitem_shape_with_channels)  \u001b[38;5;66;03m# Input for item dimensions\u001b[39;00m\n","Cell \u001b[0;32mIn[28], line 18\u001b[0m, in \u001b[0;36mitem_cnn\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv3D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39mkernel_size, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x)\n\u001b[1;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mMaxPooling3D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))(x)  \u001b[38;5;66;03m# Downsample features\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv3D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mMaxPooling3D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))(x)  \u001b[38;5;66;03m# Further downsample\u001b[39;00m\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mFlatten()(x)  \u001b[38;5;66;03m# Convert to 1D vector for efficient combination\u001b[39;00m\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:1020\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1017\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1019\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m-> 1020\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"conv3d_8\" (type Conv3D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv3d_8/Conv3D}} = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1, 1]](Placeholder, conv3d_8/Conv3D/ReadVariableOp)' with input shapes: [?,4,4,1,32], [2,2,2,32,64].\n\nCall arguments received by layer \"conv3d_8\" (type Conv3D):\n  • inputs=tf.Tensor(shape=(None, 4, 4, 1, 32), dtype=float32)"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from spektral.layers import GCNConv\n","def train_model(model, train_data, validation_data, epochs, batch_size, checkpoint_filepath):\n","  \"\"\"\n","  Trains the model on the provided data, utilizing the entire GPU's processing power and saving checkpoints.\n","  \"\"\"\n","  # Define loss function (customizable for box packing problem)\n","  def box_packing_loss(y_true, y_pred):\n","    box_dims_pred, cost_factor_pred = y_pred\n","    box_dims_true = y_true[0]  # Assuming true box dimensions are the first element in y_true\n","    # ... (Wasted space and cost calculation logic)\n","    return loss\n","\n","  # Configure GPU usage (modify as needed based on your GPU and environment)\n","  physical_devices = tf.config.list_physical_devices('GPU')\n","  try:\n","    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n","  except:\n","    # Ignore errors if setting memory growth is not supported\n","    pass\n","\n","  # Create a MirroredStrategy for multi-GPU training (if applicable)\n","  if len(physical_devices) > 1:\n","    strategy = tf.distribute.MirroredStrategy(devices=physical_devices)\n","  else:\n","    strategy = tf.distribute.get_strategy()  # Use default strategy (likely single GPU)\n","\n","  # Wrap the model in the distribution strategy\n","  with strategy.scope():\n","    # Compile the model with loss function and optimizer\n","    model.compile(loss=box_packing_loss, optimizer=\"adam\")\n","\n","    # Checkpoint callback configuration\n","    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=checkpoint_filepath,\n","        save_weights_only=True,  # Save only model weights for efficiency\n","        monitor='val_loss',  # Monitor validation loss for checkpointing\n","        mode='min',  # Save checkpoint when validation loss improves\n","        verbose=1  # Print information about the checkpoint saving process\n","    )\n","\n","    # Train the model with early stopping and checkpointing\n","    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n","    model.fit(train_data, validation_data=validation_data, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping, checkpoint_callback])\n","\n","# Example usage\n","item_shape = (10, 10, 5)  # Replace with your item dimension shape\n","item_embedding_dim = 64\n","epochs = 20  # Specify the desired number of epochs here\n","batch_size = 32\n","checkpoint_filepath = \"/kaggle/working/\" # Adjust based on your model architecture\n","\n","from sklearn.model_selection import train_test_split\n","\n","def split_data(data, test_size=0.2, val_size=0.1):\n","  \"\"\"\n","  Splits the provided data into training, validation, and test sets.\n","\n","  Args:\n","      data: A list or NumPy array containing your entire dataset.\n","      test_size: The proportion of data to be used for the test set (default: 0.2).\n","      val_size: The proportion of data to be used for the validation set (default: 0.1).\n","\n","  Returns:\n","      A tuple containing three elements: training_data, validation_data, test_data.\n","  \"\"\"\n","\n","  # Combine training and validation sets first (optional)\n","  train_val_data, test_data = train_test_split(data, test_size=test_size, random_state=42)\n","\n","  # Further split the training/validation set into training and validation sets (optional)\n","  if val_size > 0:\n","      train_data, validation_data = train_test_split(train_val_data, test_size=val_size/(1-test_size), random_state=42)\n","\n","  return train_data, validation_data, test_data # Implement data splitting function\n","\n","model = create_model(item_shape, item_embedding_dim)\n","train_model(model, train_data, validation_data, epochs=20, batch_size=32)\n","\n","# Evaluate the model on the test data (optional)\n","model.evaluate(test_data)\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
